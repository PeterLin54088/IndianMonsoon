{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Legacy Code Maintainence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streamfunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UNITEST_streamfunction_global(fname):\n",
    "    dataset = Dataset(os.path.join(path_ERA5, fname))\n",
    "    pressure = dataset[\"plev\"][::-1]\n",
    "    thickness = np.diff(np.insert(pressure, 0, 0))\n",
    "    lat = dataset[\"lat\"][:]\n",
    "    v_div = dataset[\"v\"][:, ::-1, :, -1]\n",
    "    tmp = np.insert(v_div, 0, 0, axis=1)\n",
    "    v_div_interp = (tmp[:, :-1, :] + tmp[:, 1:, :]) / 2\n",
    "    weighting = 2 * np.pi * 6.371e6 * np.cos(np.deg2rad(lat)) / 9.81\n",
    "    streamfunction = np.swapaxes(v_div_interp, 1, -1) * thickness\n",
    "    streamfunction = np.cumsum(streamfunction, axis=-1)\n",
    "    streamfunction = np.swapaxes(streamfunction, -1, 1) * weighting\n",
    "    streamfunction_convolution = moving_average(streamfunction, axis=0)\n",
    "    return streamfunction, streamfunction_convolution\n",
    "\n",
    "\n",
    "def UNITEST_streamfunction_regional(fname):\n",
    "    dataset = nc.Dataset(os.path.join(path_ERA5, fname))\n",
    "    pressure = dataset[\"plev\"][::-1]\n",
    "    thickness = np.diff(np.insert(pressure, 0, 0))\n",
    "    lon = dataset[\"lon\"][:]\n",
    "    lat = dataset[\"lat\"][:]\n",
    "    v_div = dataset[\"v\"][:, ::-1, :, :]\n",
    "    tmp = np.mean(v_div, axis=-1)\n",
    "    tmp = np.insert(tmp, 0, 0, axis=1)\n",
    "    v_div_interp = (tmp[:, :-1, :] + tmp[:, 1:, :]) / 2\n",
    "    weighting = np.deg2rad(lon[-1] - lon[0]) * 6.371e6 * np.cos(np.deg2rad(lat)) / 9.81\n",
    "    streamfunction = np.swapaxes(v_div_interp, 1, -1) * thickness\n",
    "    streamfunction = np.cumsum(streamfunction, axis=-1)\n",
    "    streamfunction = np.swapaxes(streamfunction, -1, 1) * weighting\n",
    "    streamfunction_convolution = moving_average(streamfunction, axis=0)\n",
    "\n",
    "    return streamfunction, streamfunction_convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tropical Depression Occurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_occurrence(filepath: str) -> tuple[np.ndarray, np.ndarray]:\n",
    "    from utils import moving_average, split_dimension\n",
    "    from pandas import read_csv\n",
    "\n",
    "    dataframe = read_csv(filepath, sep=\"\\t\", on_bad_lines=\"skip\", header=None)\n",
    "    dataframe.columns = [\"Year\", \"Month\", \"Day\", \"Occurrence\", \"Time\"]\n",
    "    dataframe = dataframe.astype(int)\n",
    "\n",
    "    occurrence_raw = dataframe[\"Occurrence\"].to_numpy()\n",
    "    occurrence_smoothed = moving_average(occurrence_raw, axis=0)\n",
    "\n",
    "    occurrence_raw = split_dimension(occurrence_raw, axis=0)\n",
    "    occurrence_smoothed = split_dimension(occurrence_smoothed, axis=0)\n",
    "\n",
    "    return occurrence_raw, occurrence_smoothed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Equivalent) Potential Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_potential_temperature(\n",
    "    filepath: str,\n",
    ") -> tuple[np.ndarray, np.ndarray, dict[str, np.ndarray]]:\n",
    "    \"\"\"\n",
    "    Calculate the potential temperature for a specific geographical region using latitude and longitude boundaries.\n",
    "\n",
    "    This function slices data to focus on a region defined by `INDIAN_MASK` and calculates the potential temperature.\n",
    "    Assumes 43 years of data with 365 days per year.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    filepath: str\n",
    "        Path to the NetCDF file containing potential temperature and dimensional data.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    tuple[np.ndarray, np.ndarray, dict[str, np.ndarray]]:\n",
    "        - potential_temperature: np.ndarray\n",
    "            The extracted and processed potential temperature data.\n",
    "        - potential_temperature_smoothed: np.ndarray\n",
    "            Smoothed version of the potential temperature.\n",
    "        - dims: dict[str, np.ndarray]\n",
    "            Dictionary containing dimension data (time, lat, lon, plev).\n",
    "    \"\"\"\n",
    "\n",
    "    # Local imports\n",
    "    from utils import moving_average, split_dimension\n",
    "    from constants import INDIAN_MASK\n",
    "\n",
    "    # Open the dataset and extract dimensions\n",
    "    with Dataset(filepath) as dataset:\n",
    "        dims = {dim: dataset[dim][:] for dim in dataset[\"pt\"].dimensions}\n",
    "        data_slice = [slice(None)] * len(dims)  # Initialize data slice for indexing\n",
    "\n",
    "        # Slice latitude and longitude based on the INDIAN_MASK region\n",
    "        for idx, dim in enumerate(dataset[\"pt\"].dimensions):\n",
    "            if dim == \"time\" or dim == \"plev\":\n",
    "                continue  # Skip time and pressure dimensions\n",
    "            elif dim == \"lat\":\n",
    "                # Slice latitude based on the INDIAN_MASK region\n",
    "                data_slice[idx] = (dims[dim] <= INDIAN_MASK.LATITUDE_NORTH) & (\n",
    "                    dims[dim] >= INDIAN_MASK.LATITUDE_SOUTH\n",
    "                )\n",
    "                dims[dim] = dims[dim][data_slice[idx]]\n",
    "            elif dim == \"lon\":\n",
    "                # Slice longitude based on the INDIAN_MASK region\n",
    "                data_slice[idx] = (dims[dim] <= INDIAN_MASK.LONGITUDE_EAST) & (\n",
    "                    dims[dim] >= INDIAN_MASK.LONGITUDE_WEST\n",
    "                )\n",
    "                dims[dim] = dims[dim][data_slice[idx]]\n",
    "\n",
    "        # Extract the potential temperature data with the applied slices\n",
    "        potential_temperature = dataset[\"pt\"][tuple(data_slice)]\n",
    "    # Average over the longitude axis (axis 3)\n",
    "    potential_temperature = np.mean(potential_temperature, axis=3)\n",
    "\n",
    "    # Apply moving average smoothing over the time axis (axis 0)\n",
    "    potential_temperature_smoothed = moving_average(potential_temperature, axis=0)\n",
    "\n",
    "    # Split the potential temperature and smoothed data over time (axis 0)\n",
    "    potential_temperature = split_dimension(potential_temperature, axis=0)\n",
    "    potential_temperature_smoothed = split_dimension(\n",
    "        potential_temperature_smoothed, axis=0\n",
    "    )\n",
    "\n",
    "    # Convert pressure levels from Pa to hPa\n",
    "    dims[\"plev\"] /= 100\n",
    "\n",
    "    # Return the potential temperature, its smoothed version, and the dimension data\n",
    "    return (\n",
    "        potential_temperature,\n",
    "        potential_temperature_smoothed,\n",
    "        dims,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_equivalent_potential_temperature(\n",
    "    filepath: str,\n",
    ") -> tuple[np.ndarray, np.ndarray, dict[str, np.ndarray]]:\n",
    "    \"\"\"\n",
    "    Calculate the equivalent potential temperature for a specific geographical region using latitude and longitude boundaries.\n",
    "\n",
    "    This function slices data to focus on a region defined by `INDIAN_MASK` and calculates the equivalent potential temperature.\n",
    "    Assumes 43 years of data with 365 days per year.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    filepath: str\n",
    "        Path to the NetCDF file containing equivalent potential temperature and dimensional data.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    tuple[np.ndarray, np.ndarray, dict[str, np.ndarray]]:\n",
    "        - equivalent_potential_temperature: np.ndarray\n",
    "            The extracted and processed equivalent potential temperature data.\n",
    "        - equivalent_potential_temperature_smoothed: np.ndarray\n",
    "            Smoothed version of the equivalent potential temperature.\n",
    "        - dims: dict[str, np.ndarray]\n",
    "            Dictionary containing dimension data (time, lat, lon, plev).\n",
    "    \"\"\"\n",
    "\n",
    "    # Local imports\n",
    "    from utils import moving_average, split_dimension\n",
    "    from constants import INDIAN_MASK\n",
    "\n",
    "    # Open the dataset and extract dimensions\n",
    "    with Dataset(filepath) as dataset:\n",
    "        dims = {dim: dataset[dim][:] for dim in dataset[\"ept\"].dimensions}\n",
    "        data_slice = [slice(None)] * len(dims)  # Initialize data slice for indexing\n",
    "\n",
    "        # Slice latitude and longitude based on the INDIAN_MASK region\n",
    "        for idx, dim in enumerate(dataset[\"ept\"].dimensions):\n",
    "            if dim == \"time\" or dim == \"plev\":\n",
    "                continue  # Skip time and pressure dimensions\n",
    "            elif dim == \"lat\":\n",
    "                # Slice latitude based on the INDIAN_MASK region\n",
    "                data_slice[idx] = (dims[dim] <= INDIAN_MASK.LATITUDE_NORTH) & (\n",
    "                    dims[dim] >= INDIAN_MASK.LATITUDE_SOUTH\n",
    "                )\n",
    "                dims[dim] = dims[dim][data_slice[idx]]\n",
    "            elif dim == \"lon\":\n",
    "                # Slice longitude based on the INDIAN_MASK region\n",
    "                data_slice[idx] = (dims[dim] <= INDIAN_MASK.LONGITUDE_EAST) & (\n",
    "                    dims[dim] >= INDIAN_MASK.LONGITUDE_WEST\n",
    "                )\n",
    "                dims[dim] = dims[dim][data_slice[idx]]\n",
    "\n",
    "        # Extract the equivalent potential temperature data with the applied slices\n",
    "        equivalent_potential_temperature = dataset[\"ept\"][tuple(data_slice)]\n",
    "\n",
    "    # Average over the longitude axis (axis 3)\n",
    "    equivalent_potential_temperature = np.mean(equivalent_potential_temperature, axis=3)\n",
    "\n",
    "    # Apply moving average smoothing over the time axis (axis 0)\n",
    "    equivalent_potential_temperature_smoothed = moving_average(\n",
    "        equivalent_potential_temperature, axis=0\n",
    "    )\n",
    "\n",
    "    # Split the equivalent potential temperature and smoothed data over time (axis 0)\n",
    "    equivalent_potential_temperature = split_dimension(\n",
    "        equivalent_potential_temperature, axis=0\n",
    "    )\n",
    "    equivalent_potential_temperature_smoothed = split_dimension(\n",
    "        equivalent_potential_temperature_smoothed, axis=0\n",
    "    )\n",
    "\n",
    "    # Convert pressure levels from Pa to hPa\n",
    "    dims[\"plev\"] /= 100\n",
    "\n",
    "    # Return the equivalent potential temperature, its smoothed version, and the dimension data\n",
    "    return (\n",
    "        equivalent_potential_temperature,\n",
    "        equivalent_potential_temperature_smoothed,\n",
    "        dims,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "__MAIN__",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
